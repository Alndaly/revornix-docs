# Revornix Architecture Overview

This document is organized based on the current repository code and `docker-compose.yaml` plus each service's `.env.example` files.

---

## 1. System Components and Responsibilities

- Web frontend (Next.js): UI and interaction layer; entry at `web`, build-time `NEXT_PUBLIC_*` injection.
- API backend (FastAPI): core business and data orchestration; entry at `api/main.py`, provides docs, columns, AI, graph, notifications, and more.
- Celery worker: async and heavy tasks; entry at `celery-worker/common/celery/app.py`, handles embedding, summaries, graphs, podcasts, notifications.
- Hot News service (Node): aggregation service; entry at `hot-news/src/index.ts`, provides ranking APIs.
- Nginx (optional): reverse proxy and unified entry; config at `nginx/nginx.conf`.
- MCP (built-in): MCP client/server capability inside the API, routes at `api/mcp_router/*`.

---

## 2. Data and Infrastructure

- PostgreSQL: primary business data store; ORM models in `api/models` and `celery-worker/models`.
- Redis: cache and task queue (Celery broker/backend), config in `api/config/redis.py` and `celery-worker/config/redis.py`.
- Milvus: vector search and similarity, config in `api/config/milvus.py`.
- Neo4j: knowledge graph storage/query, config in `api/config/neo4j.py`.
- MinIO (file-backend): default file system and object storage, controlled by `FILE_SYSTEM_*`.
- Optional external object storage: AWS S3 / Aliyun OSS / generic S3; logic in `api/file/*` and `celery-worker/file/*`.

---

## 3. Core Requests and Data Flow

1. User request from Web -> API handles business logic -> reads/writes PostgreSQL/Redis/Milvus/Neo4j -> returns response.
2. Document/column processing -> API enqueues Celery task -> worker parses/summarizes/embeds/builds graph/podcasts -> writes results and notifies.
3. File upload/access -> API generates file URL -> MinIO or external storage read/write -> frontend accesses via public URL.
4. Hot News ranking -> Web calls Hot News service -> service aggregates data and returns list.

---

## 4. Deployment Topology (Default Docker Compose)

- `web`: frontend container, depends on `api` and `file-backend`.
- `api`: main backend container, depends on `postgres`, `redis`, `neo4j`, `milvus`.
- `celery-worker`: task worker, depends on `postgres`, `redis`, `neo4j`, `milvus`.
- `hot-news`: aggregation service.
- `file-backend`: MinIO file system.
- `postgres`, `redis`, `neo4j`, `milvus`, `etcd`, `minio`: infrastructure components.
- `nginx`: unified entry and routing.
- `rsshub` + `browserless`: RSSHub crawler and browser dependencies.

---

## 5. Observability and Extension Points

- Sentry: enable per API and worker via `API_SENTRY_*` and `WORKER_SENTRY_*`.
- Langfuse: trace requests via `LANGFUSE_*`.
- Model providers: multi-model/provider support; built-in initialization in `api/data/sql/create.py`.
- Third-party login and SMS/email: Google/GitHub/WeChat/Tencent SMS/SMTP integrated at the API layer.

---

## 6. Initialization and Startup Flow (Brief)

1. Prepare `.env` and each service `.env`.
2. Start base services (Postgres/Redis/Neo4j/Milvus/MinIO).
3. Run `api/data/milvus/create` and `api/data/sql/create` to initialize data.
4. Start API, worker, web, and Hot News.
